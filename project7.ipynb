{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Music section is the second half of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Attribute Information:</strong>\n",
    "\n",
    "- ID number\n",
    "- Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "<strong>Ten real-valued features are computed for each cell nucleus:</strong>\n",
    "\n",
    "- radius (mean of distances from center to points on the perimeter)\n",
    "- texture (standard deviation of gray-scale values)\n",
    "- perimeter\n",
    "- area\n",
    "- smoothness (local variation in radius lengths)\n",
    "- compactness (perimeter^2 / area - 1.0)\n",
    "- concavity (severity of concave portions of the contour)\n",
    "- concave points (number of concave portions of the contour)\n",
    "- symmetry\n",
    "- fractal dimension (\"coastline approximation\" - 1)\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Loading Libraries and Utilies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-10T16:34:33.037959Z",
     "iopub.status.busy": "2021-06-10T16:34:33.037573Z",
     "iopub.status.idle": "2021-06-10T16:35:07.746813Z",
     "shell.execute_reply": "2021-06-10T16:35:07.745650Z",
     "shell.execute_reply.started": "2021-06-10T16:34:33.037928Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Base libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display_html\n",
    "\n",
    "\n",
    "## visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# stat tools\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import kurtosis, skew\n",
    "\n",
    "## preprocessing & otherlibraries\n",
    "from sklearn.model_selection import (train_test_split)\n",
    "\n",
    "\n",
    "## data sampling and outlier detection libraries\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "#from umap import UMAP\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# modeling\n",
    "from sklearn.linear_model import (LogisticRegression, LinearRegression) \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import (r2_score, \n",
    "                             accuracy_score)\n",
    "\n",
    "## plot settings\n",
    "\n",
    "sns.set_style('white')\n",
    "mpl.rcParams['xtick.labelsize'] = 12\n",
    "mpl.rcParams['ytick.labelsize'] = 12\n",
    "mpl.rcParams['axes.spines.left'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.bottom'] = False\n",
    "plt.rcParams.update({'font.size':14})\n",
    "plt.rcParams['font.weight']= 'normal'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:07.749185Z",
     "iopub.status.busy": "2021-06-10T16:35:07.748752Z",
     "iopub.status.idle": "2021-06-10T16:35:07.781685Z",
     "shell.execute_reply": "2021-06-10T16:35:07.779709Z",
     "shell.execute_reply.started": "2021-06-10T16:35:07.749139Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('breast_cancer.csv', delimiter = ',', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Values and NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:07.784475Z",
     "iopub.status.busy": "2021-06-10T16:35:07.783981Z",
     "iopub.status.idle": "2021-06-10T16:35:07.800248Z",
     "shell.execute_reply": "2021-06-10T16:35:07.799253Z",
     "shell.execute_reply.started": "2021-06-10T16:35:07.784424Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:07.802845Z",
     "iopub.status.busy": "2021-06-10T16:35:07.802213Z",
     "iopub.status.idle": "2021-06-10T16:35:07.832525Z",
     "shell.execute_reply": "2021-06-10T16:35:07.831339Z",
     "shell.execute_reply.started": "2021-06-10T16:35:07.802797Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns = ['Unnamed: 32'], inplace = True)\n",
    "df['diagnosis'] = df['diagnosis'].map({'B':0, 'M':1})\n",
    "\n",
    "print(df.head(2).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:07.835933Z",
     "iopub.status.busy": "2021-06-10T16:35:07.835635Z",
     "iopub.status.idle": "2021-06-10T16:35:07.847295Z",
     "shell.execute_reply": "2021-06-10T16:35:07.846101Z",
     "shell.execute_reply.started": "2021-06-10T16:35:07.835904Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('\\nTotal Number of Null values: \\n' +  str(df.isnull().sum().sum()))\n",
    "print('\\nAny NUll Value columns: \\n' + str(df.isnull().sum().any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive Statistics of The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:07.848964Z",
     "iopub.status.busy": "2021-06-10T16:35:07.848660Z",
     "iopub.status.idle": "2021-06-10T16:35:08.026435Z",
     "shell.execute_reply": "2021-06-10T16:35:08.025644Z",
     "shell.execute_reply.started": "2021-06-10T16:35:07.848933Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare the dataset for descriptive statistics\n",
    "stats_df = df.drop(columns=['id']).describe().T.reset_index().rename(columns={'index': 'Features'})\n",
    "stats_df['count'] = stats_df['count'].astype(int)\n",
    "\n",
    "# Style the DataFrame\n",
    "style = stats_df.style.set_table_attributes(\"style='display:inline'\") \\\n",
    "                     .bar(subset=['mean', 'std', 'min', '25%', '50%', '75%', 'max'], axis=1, color='#fed766') \\\n",
    "                     .format({\n",
    "                         'mean': \"{:20,.3f}\",\n",
    "                         'std': \"{:20,.3f}\",\n",
    "                         'min': \"{:20,.3f}\",\n",
    "                         '25%': \"{:20,.3f}\",\n",
    "                         '50%': \"{:20,.3f}\",\n",
    "                         '75%': \"{:20,.3f}\",\n",
    "                         'max': \"{:20,.3f}\"\n",
    "                     }) \\\n",
    "                     .format({\"Features\": lambda x: x.upper()}) \\\n",
    "                     .set_properties(**{'background-color': 'white', 'color': 'black'})\n",
    "\n",
    "# Display the styled DataFrame\n",
    "display_html(style._repr_html_(), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Color Palette for visualizaitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:08.028123Z",
     "iopub.status.busy": "2021-06-10T16:35:08.027658Z",
     "iopub.status.idle": "2021-06-10T16:35:08.206626Z",
     "shell.execute_reply": "2021-06-10T16:35:08.205546Z",
     "shell.execute_reply.started": "2021-06-10T16:35:08.028090Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "colors= ['#fe4a49' ,'#2ab7ca' ,'#fed766' ,'#e6e6ea' ,'#f4f4f8']\n",
    "\n",
    "sns.palplot(colors,size = 3)\n",
    "\n",
    "plt.gcf().set_size_inches(15,5)\n",
    "\n",
    "plt.text(-0.75,-0.75, 'Color Palette',{'fontfamily':'serif', 'size':24, 'weight':'bold'})\n",
    "plt.text(-0.75,-0.68, 'Lets try to stick to these colors throughout presentation.',{'fontfamily':'serif', 'size':16},alpha = 0.9)\n",
    "for idx,values in enumerate(colors):\n",
    "    plt.text(idx-0.25,0, colors[idx],{'fontfamily':'serif', 'size':16, 'weight':'bold','color':'black'}, alpha =0.8)\n",
    "plt.gcf().set_facecolor('white')\n",
    "plt.box(None)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:08.209263Z",
     "iopub.status.busy": "2021-06-10T16:35:08.208970Z",
     "iopub.status.idle": "2021-06-10T16:35:08.215891Z",
     "shell.execute_reply": "2021-06-10T16:35:08.214871Z",
     "shell.execute_reply.started": "2021-06-10T16:35:08.209234Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Null accuracy score for current data\n",
    "NUll_acc = round(max(df.diagnosis.values.mean(), 1 - df.diagnosis.values.mean()), 2)\n",
    "\n",
    "print('\\nNull Accuracy Score: ' + str(NUll_acc) + '\\n')\n",
    "print('This is the baseline our model needs to cross.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Exploration and Explinatory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My strategy for this analysis as follows\n",
    "<ul>\n",
    "    <li>Target Distribution</li>\n",
    "    <li>Univariate Analysis</li>\n",
    "    <li>Binary Feature Analysis</li>\n",
    "    <li>Multivariate Analysis</li>\n",
    "    <li>Class Segregation with Dimensionality Reduction </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Distribution of Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "feat_df = df.drop(columns=['id', 'diagnosis'])\n",
    "tar_df = df['diagnosis']\n",
    "cancer_dist = round(tar_df.value_counts(normalize=True), 2) * 100\n",
    "\n",
    "# Create a bar plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "bars = ax.bar(['Healthy', 'Cancerous'], cancer_dist.values, color=[colors[2], colors[0]])\n",
    "\n",
    "# Add labels to each bar\n",
    "for bar, percentage in zip(bars, cancer_dist.values):\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2, \n",
    "        bar.get_height() - 5, \n",
    "        f'{percentage}%', \n",
    "        ha='center', \n",
    "        va='top', \n",
    "        fontsize=12, \n",
    "        fontweight='bold', \n",
    "        color='white'\n",
    "    )\n",
    "\n",
    "# Titles and descriptive text\n",
    "ax.set_title('How Susceptible Are Women To Breast Cancer?', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Add legend\n",
    "ax.legend(['Healthy', 'Cancerous'], loc='upper right')\n",
    "\n",
    "# Remove unnecessary axes for a cleaner look\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Univariate Analysis of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:08.684935Z",
     "iopub.status.busy": "2021-06-10T16:35:08.684366Z",
     "iopub.status.idle": "2021-06-10T16:35:13.541067Z",
     "shell.execute_reply": "2021-06-10T16:35:13.539854Z",
     "shell.execute_reply.started": "2021-06-10T16:35:08.684889Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=10, ncols=3, figsize=(12, 24), dpi=80)\n",
    "axes = ax.ravel()\n",
    "\n",
    "# Loop through each feature column and corresponding axis\n",
    "for col, ax in zip(feat_df.columns, axes):\n",
    "    \n",
    "    # Determine color based on skewness\n",
    "    color = colors[0] if skew(feat_df[col]) > 1 else colors[1]\n",
    "    \n",
    "    # Violin plot\n",
    "    sns.violinplot(data=feat_df, x=col, ax=ax, color=color, cut=0, inner='box', linewidth=3)\n",
    "    \n",
    "    # Plot settings\n",
    "    xlabel = ' '.join([word.capitalize() for word in col.split('_')])\n",
    "    ax.set_xlabel(xlabel, fontsize=14, fontweight='bold')\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=3, h_pad=2.5, w_pad=2.5)\n",
    "\n",
    "# Titles and additional text\n",
    "fig.suptitle('Overview of Univariate Feature Distribution', fontsize=22, fontweight='bold', x=0.5, y=1.02)\n",
    "fig.text(0.65, 1, \"Skewed\", fontsize=16, fontweight='bold', color=colors[0])\n",
    "fig.text(0.73, 1, '|', fontsize=16, fontweight='bold')\n",
    "fig.text(0.74, 1, \"Relative Normal\", fontsize=16, fontweight='bold', color=colors[1])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T19:20:21.881301Z",
     "iopub.status.busy": "2021-05-26T19:20:21.880789Z",
     "iopub.status.idle": "2021-05-26T19:20:21.884785Z",
     "shell.execute_reply": "2021-05-26T19:20:21.883886Z",
     "shell.execute_reply.started": "2021-05-26T19:20:21.88127Z"
    }
   },
   "source": [
    "## 2.3 Univariate Analysis of Features wrt Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:13.543352Z",
     "iopub.status.busy": "2021-06-10T16:35:13.542859Z",
     "iopub.status.idle": "2021-06-10T16:35:18.874710Z",
     "shell.execute_reply": "2021-06-10T16:35:18.873889Z",
     "shell.execute_reply.started": "2021-06-10T16:35:13.543302Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=10, ncols=3, figsize=(12, 24), dpi=80)\n",
    "axes = ax.ravel()\n",
    "\n",
    "# Loop through each feature column and corresponding axis\n",
    "for col, ax in zip(feat_df.columns, axes):\n",
    "    \n",
    "    # KDE plot with hue for diagnosis\n",
    "    sns.kdeplot(\n",
    "        data=df, x=col, ax=ax, shade=True,\n",
    "        palette=[colors[0], colors[2]],\n",
    "        alpha=0.95, linewidth=3, ec='black',\n",
    "        hue='diagnosis', hue_order=[1, 0],\n",
    "        legend=False\n",
    "    )\n",
    "    \n",
    "    # Plot settings\n",
    "    xlabel = ' '.join([value.capitalize() for value in str(col).split('_')])\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    ax.set_xlabel(xlabel, fontsize=14, fontweight='bold')\n",
    "   \n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=3, h_pad=1.5, w_pad=1.5)\n",
    "\n",
    "# Titles and additional text\n",
    "fig.suptitle('Distribution of Cancer Cells on Feature Level', fontsize=22, fontweight='bold', x=0.5, y=1.03)\n",
    "\n",
    "fig.text(0.615, 1, \"Cancerous\", fontsize=16, fontweight='bold', color=colors[0], alpha=1)\n",
    "fig.text(0.73, 1, '|', fontsize=16, fontweight='bold')\n",
    "fig.text(0.74, 1, \"Healthy\", fontsize=16, fontweight='bold', color=colors[2], alpha=1)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T18:05:44.047121Z",
     "iopub.status.busy": "2021-05-26T18:05:44.046767Z",
     "iopub.status.idle": "2021-05-26T18:05:44.05131Z",
     "shell.execute_reply": "2021-05-26T18:05:44.050623Z",
     "shell.execute_reply.started": "2021-05-26T18:05:44.047091Z"
    }
   },
   "source": [
    "## 2.4 Multivariate Analysis of Features In Same Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Featues Segregation based on mean,se,and worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:18.876365Z",
     "iopub.status.busy": "2021-06-10T16:35:18.875924Z",
     "iopub.status.idle": "2021-06-10T16:35:18.892711Z",
     "shell.execute_reply": "2021-06-10T16:35:18.891587Z",
     "shell.execute_reply.started": "2021-06-10T16:35:18.876318Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Measurement and characteristics keyword lists\n",
    "measure_keyword = ['radius', 'perimeter', 'area', 'concavity', 'concave points']\n",
    "character_keyword = ['texture', 'smoothness', 'compactness', 'symmetry', 'fractal']\n",
    "\n",
    "# Mean, standard error, and worst measure feature lists\n",
    "mean_measure, mean_character = ['diagnosis'], ['diagnosis']\n",
    "se_measure, se_character = ['diagnosis'], ['diagnosis']\n",
    "worst_measure, worst_character = ['diagnosis'], ['diagnosis']\n",
    "\n",
    "# Loop to create required mean, standard error, and worst measure features\n",
    "for col in feat_df.columns:\n",
    "    name_list = str(col).split('_')\n",
    "    \n",
    "    if name_list[0] in measure_keyword:\n",
    "        if 'mean' in name_list:\n",
    "            mean_measure.append(col)\n",
    "        elif 'se' in name_list:\n",
    "            se_measure.append(col)\n",
    "        else:\n",
    "            worst_measure.append(col)           \n",
    "    \n",
    "    if name_list[0] in character_keyword:\n",
    "        if 'mean' in name_list:\n",
    "            mean_character.append(col)\n",
    "        elif 'se' in name_list:\n",
    "            se_character.append(col)\n",
    "        else:\n",
    "            worst_character.append(col) \n",
    "            \n",
    "# Descriptions and lists\n",
    "print('\\nSeparated Features are stored into lists:\\n')\n",
    "print('Mean of Measurements: ' + ', '.join(mean_measure[1:]) + '\\n')\n",
    "print('Mean of Characteristics: ' + ', '.join(mean_character[1:]) + '\\n')\n",
    "print('Standard Error of Measurements: ' + ', '.join(se_measure[1:]) + '\\n')\n",
    "print('Standard Error of Characteristics: ' + ', '.join(se_character[1:]) + '\\n')\n",
    "print('Worst of Measurements: ' + ', '.join(worst_measure[1:]) + '\\n')\n",
    "print('Worst of Characteristics: ' + ', '.join(worst_character[1:]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Mean Columns with diagnosis\n",
    "m_col = ['diagnosis','radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\n",
    "\n",
    "# Getting Se Columns with diagnosis\n",
    "s_col = ['diagnosis','radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "       'fractal_dimension_se']\n",
    "\n",
    "# Getting Worst column with diagnosis\n",
    "w_col = ['diagnosis','radius_worst', 'texture_worst',\n",
    "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "       'symmetry_worst', 'fractal_dimension_worst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot for mean columns\n",
    "sns.pairplot(df[m_col], hue='diagnosis', palette=[colors[0], colors[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot for se columns\n",
    "sns.pairplot(df[s_col], hue='diagnosis', palette=[colors[0], colors[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot for worst columns\n",
    "sns.pairplot(df[w_col], hue='diagnosis', palette=[colors[0], colors[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Correlation Based Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the analysis of single category features, lets try to make things more interesting with bringing correlation into the picture. lets try to get the high positively correlated nad negatively correlated features and see how are they correlated to each other. This is crutial for understanding the collinearity of the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:47.468674Z",
     "iopub.status.busy": "2021-06-10T16:35:47.468267Z",
     "iopub.status.idle": "2021-06-10T16:35:47.502239Z",
     "shell.execute_reply": "2021-06-10T16:35:47.501541Z",
     "shell.execute_reply.started": "2021-06-10T16:35:47.468640Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temp_df = df.corr().unstack().reset_index()\n",
    "\n",
    "\n",
    "### cross relational positive features\n",
    "\n",
    "positive_corr_df = (temp_df[(temp_df[0]>0.9) &\n",
    "         (temp_df['level_0'] != temp_df['level_1']) & \n",
    "         ((temp_df['level_0'].apply(lambda x: str(x).split('_')[-1])) != (temp_df['level_1'].apply(lambda x: str(x).split('_')[-1])))])\n",
    "\n",
    "positive_corr_df['z'] = positive_corr_df.apply(lambda x: tuple(sorted([x['level_0'],x['level_1']])), axis = 1)\n",
    "positive_corr_df.drop_duplicates(subset=\"z\", keep=\"first\" , inplace = True ) \n",
    "positive_corr_df.drop(columns = ['z'], inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "### cross relational negative features\n",
    "\n",
    "negative_corr_df = (temp_df[(temp_df[0]<-0.2) &\n",
    "         (temp_df['level_0'] != temp_df['level_1']) & \n",
    "         ((temp_df['level_0'].apply(lambda x: str(x).split('_')[-1])) != (temp_df['level_1'].apply(lambda x: str(x).split('_')[-1])))])\n",
    "\n",
    "negative_corr_df['z'] = negative_corr_df.apply(lambda x: tuple(sorted([x['level_0'],x['level_1']])), axis = 1)\n",
    "negative_corr_df.drop_duplicates(subset=\"z\", keep=\"first\" , inplace = True ) \n",
    "negative_corr_df.drop(columns = ['z'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:47.503690Z",
     "iopub.status.busy": "2021-06-10T16:35:47.503263Z",
     "iopub.status.idle": "2021-06-10T16:35:47.521073Z",
     "shell.execute_reply": "2021-06-10T16:35:47.519929Z",
     "shell.execute_reply.started": "2021-06-10T16:35:47.503660Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('\\nHelper function to visualize the cross categorical Feature analysis\\n')\n",
    "def plot_cross_scatter(corr_df, data =df,title = None,nrows = 4, ncols = 3, figsize = (12,24), colors = colors):\n",
    "    \n",
    "    col1_list = corr_df['level_0'].values.tolist()\n",
    "    col2_list = corr_df['level_1'].values.tolist()\n",
    "    \n",
    "    ## plotting\n",
    "    fig,axes = plt.subplots(nrows,ncols, figsize = (15,20))\n",
    "    \n",
    "    # removing the last axes\n",
    "    axes.ravel()[-1].axes.get_xaxis().set_visible(False)\n",
    "    axes.ravel()[-1].axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    for ax,col1,col2 in zip(axes.ravel(), col1_list,col2_list):\n",
    "        \n",
    "        sns.scatterplot(x= data[col1], y = data[col2], ax = ax,size = 100, \n",
    "                        linewidth= 0.5, edgecolor = 'black',\n",
    "                        hue = data['diagnosis'], hue_order = [1,0],\n",
    "                        palette = [colors[0],colors[2]], legend = False )\n",
    "        \n",
    "        ## plot setting\n",
    "        xlabel = ' '.join([value.capitalize() for value in str(col1).split('_') ])\n",
    "        ylabel = ' '.join([value.capitalize() for value in str(col2).split('_') ])\n",
    "        \n",
    "        ax.axes.set_xlabel(xlabel,{'font':'serif','size':14, 'weight':'bold'}, alpha = 1)\n",
    "        ax.axes.set_ylabel(ylabel,{'font':'serif','size':14, 'weight':'bold'}, alpha = 1) \n",
    "        \n",
    "        ax.set_xticklabels('')\n",
    "        ax.set_yticklabels('')\n",
    "        \n",
    "    \n",
    "    ## titles and text\n",
    "    fig.text(0.05,0.935,'{}'.format(title), {'font':'serif','size':22, 'weight':'bold'}, alpha = 1)\n",
    "\n",
    "    fig.text(0.63,0.885, \"Cancerous\",{'font':'serif','size':16, 'weight':'bold', 'color':colors[0]}, alpha = 1)\n",
    "    fig.text(0.735,0.885, '|',{'font':'serif','size':16, 'weight':'bold'})\n",
    "    fig.text(0.745,0.885, \"Healthy\",{'font':'serif','size':16, 'weight':'bold','color':colors[2]}, alpha = 1)\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positively Correlated CrossCategorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:47.522698Z",
     "iopub.status.busy": "2021-06-10T16:35:47.522404Z",
     "iopub.status.idle": "2021-06-10T16:35:49.247349Z",
     "shell.execute_reply": "2021-06-10T16:35:49.246112Z",
     "shell.execute_reply.started": "2021-06-10T16:35:47.522670Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_cross_scatter(positive_corr_df, title = 'CrossCategorical Positively Related Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negatively Correlated CrossCategorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:35:49.253800Z",
     "iopub.status.busy": "2021-06-10T16:35:49.253329Z",
     "iopub.status.idle": "2021-06-10T16:35:50.919088Z",
     "shell.execute_reply": "2021-06-10T16:35:50.917885Z",
     "shell.execute_reply.started": "2021-06-10T16:35:49.253753Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_cross_scatter(negative_corr_df,nrows = 4,ncols = 2, figsize=(12,6)\n",
    "                   ,title = 'CrossCategorical Negitively Correlated Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select pairs of features for visualization\n",
    "feature_pairs = [\n",
    "    (\"radius_mean\", \"texture_mean\"),\n",
    "    (\"perimeter_mean\", \"area_mean\"),\n",
    "    (\"concavity_mean\", \"concave points_mean\")\n",
    "]\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), dpi=85)\n",
    "\n",
    "for i, (feature_x, feature_y) in enumerate(feature_pairs):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # Prepare data for the selected pair of features\n",
    "    X_pair = df[[feature_x, feature_y]].values\n",
    "    y = df['diagnosis'].values\n",
    "    \n",
    "    # Fit logistic regression or SVM model to the pair of features\n",
    "    model = LogisticRegression()  # Use SVC(kernel='linear') for a linear SVM instead\n",
    "    model.fit(X_pair, y)\n",
    "\n",
    "    # Scatter plot of data points\n",
    "    sns.scatterplot(\n",
    "        x=df[feature_x], y=df[feature_y], hue=df['diagnosis'], \n",
    "        palette=colors, s=50, edgecolor='black', alpha=0.8, ax=ax, legend=False\n",
    "    )\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    x_min, x_max = X_pair[:, 0].min() - 1, X_pair[:, 0].max() + 1\n",
    "    y_min, y_max = X_pair[:, 1].min() - 1, X_pair[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, levels=[-1, 0, 1], colors=[colors[1], colors[0]], alpha=0.3)\n",
    "    \n",
    "    # Set labels and titles\n",
    "    ax.set_xlabel(\" \".join(feature_x.split('_')).capitalize(), fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(\" \".join(feature_y.split('_')).capitalize(), fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f\"{feature_x} vs {feature_y}\", fontsize=14, fontweight='bold')\n",
    "    \n",
    "fig.suptitle(\"Decision Boundaries for Selected Pairs of Features\", fontsize=18, fontweight='bold')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning Techniques And Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Outliers And Influential Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ouliers Detection and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:36:00.520709Z",
     "iopub.status.busy": "2021-06-10T16:36:00.520404Z",
     "iopub.status.idle": "2021-06-10T16:36:00.529516Z",
     "shell.execute_reply": "2021-06-10T16:36:00.528593Z",
     "shell.execute_reply.started": "2021-06-10T16:36:00.520678Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def outlier_detect(algo, data):\n",
    "    cols = data.drop(columns=['id']).columns\n",
    "    # Creating feature and target numpy arrays\n",
    "    feat, tar = data[cols].drop(columns='diagnosis').values, data['diagnosis'].values\n",
    "    # Fitting the features to algo\n",
    "    yhat = algo.fit_predict(feat)\n",
    "    # Masking the features that are not outliers\n",
    "    mask = yhat != -1\n",
    "    X, y = feat[mask, :], tar[mask]\n",
    "    data_inarray = np.append(y.reshape(-1, 1), X, axis=1)\n",
    "    return pd.DataFrame(data=data_inarray, columns=cols)\n",
    "\n",
    "def skew_sum(data):\n",
    "    return skew(data).sum()\n",
    "\n",
    "def kurtosis_sum(data):\n",
    "    return kurtosis(data).sum()\n",
    "\n",
    "def shape(data): \n",
    "    return data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:36:00.531146Z",
     "iopub.status.busy": "2021-06-10T16:36:00.530712Z",
     "iopub.status.idle": "2021-06-10T16:36:05.929670Z",
     "shell.execute_reply": "2021-06-10T16:36:05.928592Z",
     "shell.execute_reply.started": "2021-06-10T16:36:00.531116Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "outlier_algos = [\n",
    "    IsolationForest(contamination=0.05),\n",
    "    EllipticEnvelope(contamination=0.05),\n",
    "    LocalOutlierFactor(contamination=0.05),\n",
    "    DBSCAN(eps=70, min_samples=10)\n",
    "]\n",
    "\n",
    "df_list = [df.drop(columns=['id'])]\n",
    "shapes = [df.drop(columns=['id']).shape[0]]\n",
    "skews = [skew(df.drop(columns=['id']))]\n",
    "kurts = [kurtosis(df.drop(columns=['id']))]\n",
    "\n",
    "for algo in outlier_algos:\n",
    "    corrected_df = outlier_detect(algo, df)\n",
    "    df_list.append(corrected_df)\n",
    "    shapes.append(corrected_df.shape[0])\n",
    "    skews.append(skew(corrected_df))\n",
    "    kurts.append(kurtosis(corrected_df))\n",
    "        \n",
    "algorithms = ['Original', 'IsolationForest', 'EllipticEnvelope', 'LocalOutlierFactor', 'DBSCAN']\n",
    "outliers_info = pd.DataFrame({\n",
    "    'algorithms': algorithms,\n",
    "    'df_list': df_list,\n",
    "    'shapes': shapes,\n",
    "    'skews': skews,\n",
    "    'kurts': kurts\n",
    "})\n",
    "\n",
    "outliers_info['skews_sum'] = outliers_info['skews'].apply(lambda x: round(x.sum(), 2))\n",
    "outliers_info['kurts_sum'] = outliers_info['kurts'].apply(lambda x: round(x.sum(), 2))\n",
    "outliers_info.sort_values(by='shapes', inplace=True)\n",
    "outliers_info.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for idx, df_ in enumerate(outliers_info['df_list']):\n",
    "    lr = LinearRegression()\n",
    "    X = df_.drop(columns=['diagnosis'])\n",
    "    y = df_['diagnosis']\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # Linear regression\n",
    "    preds = LinearRegression().fit(xtrain.values, ytrain.values).predict(xtest.values)\n",
    "        \n",
    "    r2 = round(r2_score(ytest, preds), 3)\n",
    "    outliers_info.loc[idx, 'r2_score'] = r2\n",
    "\n",
    "print('\\nAll the corrected data is stored in the Outliers_info DataFrame\\n')\n",
    "\n",
    "print(outliers_info.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the results of outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:36:05.931636Z",
     "iopub.status.busy": "2021-06-10T16:36:05.931170Z",
     "iopub.status.idle": "2021-06-10T16:36:05.944631Z",
     "shell.execute_reply": "2021-06-10T16:36:05.943510Z",
     "shell.execute_reply.started": "2021-06-10T16:36:05.931588Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class OutlierViz:\n",
    "    \n",
    "    def __init__(self, ax, orig_feat=None, corrected_feat=None): \n",
    "        self.x_org = orig_feat\n",
    "        self.x_corr = corrected_feat\n",
    "        self.ax = ax\n",
    "\n",
    "    def visualize_data(self, name=None, r2=None, orig_r2=None):\n",
    "        \n",
    "        self.ax.set_facecolor('white')\n",
    "        \n",
    "        # Dimension reduction with PCA\n",
    "        pca1 = PCA(n_components=2).fit_transform(self.x_org)\n",
    "        pca2 = PCA(n_components=2).fit_transform(self.x_corr)\n",
    "        \n",
    "        # Plot original data points\n",
    "        self.ax.scatter(\n",
    "            pca1[:, 0], pca1[:, 1],\n",
    "            color=colors[0], s=50, alpha=0.8, edgecolor='black', linewidth=0.5, label=\"Original Data\"\n",
    "        )\n",
    "        \n",
    "        # Plot corrected data points\n",
    "        self.ax.scatter(\n",
    "            pca2[:, 0], pca2[:, 1],\n",
    "            color=colors[1], s=50, alpha=0.8, edgecolor='black', linewidth=0.5, label=\"Corrected Data\"\n",
    "        )\n",
    "   \n",
    "        # Text labels for name, R2 Score, and Original R2 Score with adjusted positioning\n",
    "        self.ax.text(0.95, 0.9, f'{name}', transform=self.ax.transAxes, ha='right', fontsize=14, fontweight='bold')\n",
    "        self.ax.text(0.95, 0.85, f'R2 Score: {r2}', transform=self.ax.transAxes, ha='right', fontsize=12)\n",
    "        self.ax.text(0.95, 0.8, f'Orig R2 Score: {orig_r2}', transform=self.ax.transAxes, ha='right', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:36:05.946394Z",
     "iopub.status.busy": "2021-06-10T16:36:05.946077Z",
     "iopub.status.idle": "2021-06-10T16:36:06.739433Z",
     "shell.execute_reply": "2021-06-10T16:36:06.738439Z",
     "shell.execute_reply.started": "2021-06-10T16:36:05.946365Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax =plt.subplots(2,2,figsize =(13,9), dpi = 70)\n",
    "axes = ax.ravel()\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "# plotting \n",
    "orig = outliers_info['df_list'][0]\n",
    "\n",
    "(OutlierViz(ax = axes[0] , orig_feat = orig, corrected_feat= outliers_info['df_list'][1])\n",
    "            .visualize_data(name = 'Isolation Forest', r2= outliers_info['r2_score'][1],orig_r2 = outliers_info['r2_score'][0]))\n",
    "\n",
    "(OutlierViz(ax = axes[1], orig_feat = orig, corrected_feat= outliers_info['df_list'][2])\n",
    " .visualize_data(name = 'Eclliptic Envelope',r2= outliers_info['r2_score'][2],orig_r2 = outliers_info['r2_score'][0]))\n",
    "\n",
    "(OutlierViz(ax = axes[2], orig_feat = orig, corrected_feat= outliers_info['df_list'][3])\n",
    " .visualize_data(name = 'Local Outlier Factor',r2= outliers_info['r2_score'][3],orig_r2 = outliers_info['r2_score'][0]))\n",
    "\n",
    "(OutlierViz(ax = axes[3], orig_feat = orig, corrected_feat= outliers_info['df_list'][4])\n",
    " .visualize_data(name = 'DBSCAN',r2= outliers_info['r2_score'][4],orig_r2 = outliers_info['r2_score'][0]))\n",
    "\n",
    "fig.text(-0.05,1.085,'Outliers and Original Data', {'font':'serif','size':22, 'weight':'bold'}, alpha = 1)\n",
    "\n",
    "fig.text(0.59,1, \"Original Data\",{'font':'serif','size':16, 'weight':'bold', 'color':colors[1]}, alpha = 1)\n",
    "fig.text(0.73,1, '|',{'font':'serif','size':16, 'weight':'bold'})\n",
    "fig.text(0.74,1, \"Corrected Data\",{'font':'serif','size':16, 'weight':'bold','color':colors[0]}, alpha = 1)\n",
    "\n",
    "fig.tight_layout(pad = 1.5, w_pad = 1.5,h_pad = 1.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Overall Skewness and Kurtosis are greatly reduced and r2 score improved slightly with Isolation forest, so lets move on with this algo and explore feature level skewness and kutotsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:36:07.213728Z",
     "iopub.status.busy": "2021-06-10T16:36:07.213431Z",
     "iopub.status.idle": "2021-06-10T16:36:08.066799Z",
     "shell.execute_reply": "2021-06-10T16:36:08.065783Z",
     "shell.execute_reply.started": "2021-06-10T16:36:07.213699Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 12))\n",
    "axes = ax.ravel()\n",
    "\n",
    "# Plotting Skewness\n",
    "axes[0].invert_xaxis()\n",
    "axes[0].barh(\n",
    "    y=df.drop(columns=['id']).columns, \n",
    "    width=outliers_info['skews'][0].tolist(), \n",
    "    color=colors[0], \n",
    "    align='center', \n",
    "    label=\"Original\"\n",
    ")\n",
    "axes[0].barh(\n",
    "    y=df.drop(columns=['id']).columns, \n",
    "    width=outliers_info['skews'][1].tolist(), \n",
    "    color=colors[1], \n",
    "    align='center', \n",
    "    label=\"Skewness\"\n",
    ")\n",
    "\n",
    "# Plotting Kurtosis\n",
    "axes[1].barh(\n",
    "    y=df.drop(columns=['id']).columns, \n",
    "    width=outliers_info['kurts'][0].tolist(), \n",
    "    color=colors[0], \n",
    "    align='center'\n",
    ")\n",
    "axes[1].barh(\n",
    "    y=df.drop(columns=['id']).columns, \n",
    "    width=outliers_info['kurts'][1].tolist(), \n",
    "    color=colors[2], \n",
    "    align='center'\n",
    ")\n",
    "\n",
    "# Customizing labels and ticks\n",
    "axes[0].set_yticklabels([])\n",
    "axes[1].set_yticklabels(\n",
    "    df.drop(columns=['id']).columns, \n",
    "    fontdict={'fontfamily': 'serif', 'fontsize': 12, 'fontweight': 'bold'}, \n",
    "    rotation=0, \n",
    "    ha='center'\n",
    ")\n",
    "axes[1].tick_params(axis='y', pad=75)\n",
    "axes[0].set_xticklabels([])\n",
    "axes[1].set_xticklabels([])\n",
    "\n",
    "# Title and annotations\n",
    "fig.text(0.1, 1.09, 'Feature Level Stats', fontsize=22, fontweight='bold', alpha=1)\n",
    "\n",
    "# Legend for Skewness and Kurtosis\n",
    "fig.text(0.27, 0.99, \"Skewness\", fontsize=18, fontweight='bold', color=colors[1])\n",
    "fig.text(0.40, 0.99, '|', fontsize=18, fontweight='bold')\n",
    "fig.text(0.45, 0.99, \"Original\", fontsize=18, fontweight='bold', color=colors[0])\n",
    "fig.text(0.60, 0.99, '|', fontsize=18, fontweight='bold')\n",
    "fig.text(0.62, 0.99, \"Kurtosis\", fontsize=18, fontweight='bold', color=colors[2])\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(pad=1, h_pad=1, w_pad=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-31T09:31:31.434013Z",
     "iopub.status.busy": "2021-05-31T09:31:31.433624Z",
     "iopub.status.idle": "2021-05-31T09:31:31.437919Z",
     "shell.execute_reply": "2021-05-31T09:31:31.436948Z",
     "shell.execute_reply.started": "2021-05-31T09:31:31.433977Z"
    }
   },
   "source": [
    "## 3.2 Correlation and Multi-Collinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now outliers are removed, and not null values exits in our data.. Now lets address the collinearity in this section. collineraity could be problematic in a regression based models so keep accuracy and roc_auc_scores aside try to play round with how to tackle his multicollinearity and feature selection...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cutsom Correlation Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:36:08.079360Z",
     "iopub.status.busy": "2021-06-10T16:36:08.078906Z",
     "iopub.status.idle": "2021-06-10T16:36:08.126498Z",
     "shell.execute_reply": "2021-06-10T16:36:08.125316Z",
     "shell.execute_reply.started": "2021-06-10T16:36:08.079316Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Correlation matrix customization\n",
    "corr_df = df.corr()\n",
    "temp_df = corr_df.stack().reset_index()\n",
    "temp_df = temp_df[temp_df[0] != 1.0].reset_index(drop=True)\n",
    "temp_df['z'] = temp_df.apply(lambda x: tuple(sorted([x['level_0'], x['level_1']])), axis=1)\n",
    "temp_df.drop_duplicates(subset=\"z\", keep=\"first\", inplace=True)\n",
    "temp_df.drop(columns=['z'], inplace=True)\n",
    "temp_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Assign colors based on correlation value\n",
    "temp_df['color'] = temp_df[0].apply(lambda x: colors[1] if x < 0.25 else (colors[2] if 0.25 < x < 0.85 else colors[0]))\n",
    "\n",
    "print('Correlation Matrix data ready for custom visualization...\\n')\n",
    "print(temp_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-06-10T16:36:08.130014Z",
     "iopub.status.busy": "2021-06-10T16:36:08.129705Z",
     "iopub.status.idle": "2021-06-10T16:36:08.939381Z",
     "shell.execute_reply": "2021-06-10T16:36:08.938362Z",
     "shell.execute_reply.started": "2021-06-10T16:36:08.129984Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=85)\n",
    "\n",
    "# Flip y-axis\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Scatter plot to represent correlation values\n",
    "ax.scatter(\n",
    "    x=temp_df['level_0'], y=temp_df['level_1'],\n",
    "    s=temp_df[0] * 100, c=temp_df['color'],\n",
    "    linewidth=1, edgecolor='black'\n",
    ")\n",
    "\n",
    "# Set tick labels\n",
    "x_vals = temp_df['level_0'].value_counts()\n",
    "y_vals = temp_df['level_1'].value_counts().sort_values()\n",
    "\n",
    "xticklabels = [' '.join(str(col).capitalize().split('_')) for col in x_vals.index]\n",
    "yticklabels = [' '.join(str(col).capitalize().split('_')) for col in y_vals.index]\n",
    "\n",
    "# Apply labels to the x and y axes\n",
    "ax.set_yticklabels(yticklabels, fontdict={'fontfamily': 'serif', 'fontsize': 10, 'fontweight': 'bold', 'color': 'black'}, alpha=0.75)\n",
    "ax.set_xticklabels(xticklabels, fontdict={'fontfamily': 'serif', 'fontsize': 10, 'fontweight': 'bold', 'color': 'black'}, rotation=90, alpha=0.75)\n",
    "\n",
    "# Titles and descriptions\n",
    "fig.text(0.1, 0.98, 'Correlation Matrix and Multi-colinearity', fontsize=20, fontweight='bold', alpha=1)\n",
    "\n",
    "# Legend text for correlation levels\n",
    "fig.text(0.37, 0.75, \"High\", fontsize=14, fontweight='bold', color=colors[0])\n",
    "fig.text(0.45, 0.75, '|', fontsize=14, fontweight='bold')\n",
    "fig.text(0.48, 0.75, \"Moderate\", fontsize=14, fontweight='bold', color=colors[2])\n",
    "fig.text(0.62, 0.75, '|', fontsize=14, fontweight='bold')\n",
    "fig.text(0.65, 0.75, \"Least\", fontsize=14, fontweight='bold', color=colors[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above correalation plot, we can see that features could be highly correlated, moderately correalated, and least correlated based on color scheme. Blanks spaces indicate negative correlations and multicolinearity exits in data. There are plenty of highly correlatid functions, so we can safely say we have multi-collinearity in our data. But what is collinearity? if the two features are highly correlated then we say we have collinearity, if same occured for multiple features then it is called multi-colliearity. In general sense, it like two parallel lines, u see both have same slope and never have a intersection point, like-wise here if two features are have same information with somekind of constant multiple or something else, can be called as colinear features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modeling Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['diagnosis'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                df.drop('diagnosis', axis=1),\n",
    "                df['diagnosis'],\n",
    "                test_size=0.2,\n",
    "                random_state=42)\n",
    "\n",
    "print(\"Shape of training set:\", X_train.shape)\n",
    "print(\"Shape of test set:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# If X_train is a DataFrame, check for NaN values using isnull\n",
    "if isinstance(X_train, pd.DataFrame):\n",
    "    print(\"NaN values in X_train before imputation:\", X_train.isnull().sum().sum())\n",
    "else:\n",
    "    print(\"NaN values in X_train before imputation:\", np.isnan(X_train).sum())\n",
    "\n",
    "# Impute missing values with the mean (or use 'median' if preferred)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Check for NaN values after imputation\n",
    "print(\"NaN values in X_train after imputation:\", np.isnan(X_train).sum())\n",
    "print(\"NaN values in X_test after imputation:\", np.isnan(X_test).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler standardizes a feature by subtracting the mean and then scaling to unit variance.(Unit variance means dividing all the values by the standard deviation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "predictions1 = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predictions1))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_acc = accuracy_score(y_test, predictions1)\n",
    "print(\"Accuracy of the Logistic Regression Model is: \", logreg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(kernel=\"rbf\")\n",
    "svc_model.fit(X_train, y_train)\n",
    "predictions5 = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predictions5))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test, predictions5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_acc = accuracy_score(y_test, predictions5)\n",
    "print(\"Accuracy of SVM model (RBF) is: \", svm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model1 = SVC(kernel=\"poly\")\n",
    "svc_model1.fit(X_train, y_train)\n",
    "predictions6 = svc_model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, predictions6))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test, predictions6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_acc1 = accuracy_score(y_test, predictions6)\n",
    "print(\"Accuracy of SVM model (Polynomial) is: \", svm_acc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logreg_acc)\n",
    "print(svm_acc)\n",
    "print(svm_acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "model_acc = [logreg_acc, svm_acc, svm_acc1]\n",
    "model_name = ['LogisticRegression', 'SVM_rbf', 'SVM_poly']\n",
    "sns.barplot(x= model_acc, y=model_name, palette='magma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('music_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "label_mapping = dict(zip(label_encoder.transform(label_encoder.classes_), label_encoder.classes_))\n",
    "print(\"Label mapping:\", label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_corr = df.drop(columns=['filename', 'label'])\n",
    "\n",
    "corr_matrix = data_for_corr.corr()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Music Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=df, x='spectral_centroid', y='spectral_bandwidth', hue='label')\n",
    "plt.title('Spectral Centroid vs Spectral Bandwidth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='label', y='mfcc1')\n",
    "plt.title('Distribution of MFCC1 by Genre')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_standardize = [\n",
    "    'tempo', 'chroma_stft', 'rmse', 'spectral_centroid', \n",
    "    'spectral_bandwidth', 'rolloff', 'zero_crossing_rate'\n",
    "] + [f'mfcc{i}' for i in range(1, 21)]\n",
    "\n",
    "for feature in features_to_standardize:\n",
    "    df[feature] = (df[feature] - df[feature].mean()) / df[feature].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tempo', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff'] + \n",
    "       [f'mfcc{i}' for i in range(1, 21)]]\n",
    "y = df['label_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test_logistic = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "lm = LogisticRegression(class_weight='balanced', multi_class='multinomial', max_iter=1000)\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logistic = lm.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Results on Test Set\")\n",
    "p, r, f, s = precision_recall_fscore_support(y_test_logistic, y_pred_logistic, labels=np.unique(y))\n",
    "for label, genre in label_mapping.items():\n",
    "    print(f\"Genre: {genre}\")\n",
    "    print(f\"  Precision: {p[label]:.4f}\")\n",
    "    print(f\"  Recall: {r[label]:.4f}\")\n",
    "    print(f\"  F-score: {f[label]:.4f}\")\n",
    "    print(f\"  Support: {s[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tempo', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff'] + \n",
    "       [f'mfcc{i}' for i in range(1, 21)]]\n",
    "y = df['label_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test_svm_linear = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm_linear = clf.predict(X_test)\n",
    "\n",
    "print(\"SVM - Linear Results on Test Set\")\n",
    "p, r, f, s = precision_recall_fscore_support(y_test_svm_linear, y_pred_svm_linear, labels=np.unique(y))\n",
    "for label, genre in label_mapping.items():\n",
    "    print(f\"Genre: {genre}\")\n",
    "    print(f\"  Precision: {p[label]:.4f}\")\n",
    "    print(f\"  Recall: {r[label]:.4f}\")\n",
    "    print(f\"  F-score: {f[label]:.4f}\")\n",
    "    print(f\"  Support: {s[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tempo', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff'] + \n",
    "       [f'mfcc{i}' for i in range(1, 21)]]\n",
    "y = df['label_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test_svm_balanced = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm_balanced = clf.predict(X_test)\n",
    "\n",
    "print(\"SVM - RBF Results on Test Set with Balanced Weights:\")\n",
    "p, r, f, s = precision_recall_fscore_support(y_test_svm_balanced, y_pred_svm_balanced, labels=np.unique(y))\n",
    "for label, genre in label_mapping.items():\n",
    "    print(f\"Genre: {genre}\")\n",
    "    print(f\"  Precision: {p[label]:.4f}\")\n",
    "    print(f\"  Recall: {r[label]:.4f}\")\n",
    "    print(f\"  F-score: {f[label]:.4f}\")\n",
    "    print(f\"  Support: {s[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['tempo', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff'] + \n",
    "       [f'mfcc{i}' for i in range(1, 21)]]\n",
    "y = df['label_encoded']\n",
    "\n",
    "custom_weights = {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 2, 9: 2}\n",
    "\n",
    "X_train, X_test, y_train, y_test_svm_rbf = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', class_weight=custom_weights)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm_rbf = clf.predict(X_test)\n",
    "\n",
    "print(\"SVM - RBF Results on Test Set with Custom Weights:\")\n",
    "p, r, f, s = precision_recall_fscore_support(y_test_svm_rbf, y_pred_svm_rbf, labels=np.unique(y))\n",
    "label_mapping = {0: 'blues', 1: 'classical', 2: 'country', 3: 'disco', 4: 'hiphop', 5: 'jazz', 6: 'metal', 7: 'pop', 8: 'reggae', 9: 'rock'}\n",
    "for label, genre in label_mapping.items():\n",
    "    print(f\"Genre: {genre}\")\n",
    "    print(f\"  Precision: {p[label]:.4f}\")\n",
    "    print(f\"  Recall: {r[label]:.4f}\")\n",
    "    print(f\"  F-score: {f[label]:.4f}\")\n",
    "    print(f\"  Support: {s[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = ['Blues', 'Classical', 'Country', 'Disco', 'Hiphop', 'Jazz', \n",
    "                'Metal', 'Pop', 'Reggae', 'Rock']\n",
    "\n",
    "mat_logistic = confusion_matrix(y_test_logistic, y_pred_logistic)\n",
    "mat_svm_linear = confusion_matrix(y_test_svm_linear, y_pred_svm_linear)\n",
    "mat_svm_rbf_balanced = confusion_matrix(y_test_svm_balanced, y_pred_svm_balanced)\n",
    "mat_svm_rbf = confusion_matrix(y_test_svm_rbf, y_pred_svm_rbf)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(mat_logistic.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(mat_svm_linear.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.title('Confusion Matrix - SVM (Linear Kernel)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(mat_svm_rbf_balanced.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.title('Confusion Matrix - SVM (RBF Kernel) Balanced')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(mat_svm_rbf.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.title('Confusion Matrix - SVM (RBF Kernel) Weighted')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
